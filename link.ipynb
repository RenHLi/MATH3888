{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the network containing all human proteins on Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"9606.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 19385\n",
      "number of edges of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of G0:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 19385\n",
      "number of edges of largest connected subgraph of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of target node:  1889\n"
     ]
    }
   ],
   "source": [
    "print(\"degree of target node: \",G0.degree('9606.ENSP00000375892'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree sequence\n",
    "degS=[G.degree()[node] for node in list(G.nodes())]\n",
    "degS.sort()\n",
    "degS=np.array(degS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 7\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partLouvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1=partLouvain['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  3409\n",
      "The size of community # 1 is  3197\n",
      "The size of community # 2 is  3408\n",
      "The size of community # 3 is  3809\n",
      "The size of community # 4 is  2181\n",
      "The size of community # 5 is  3143\n",
      "The size of community # 6 is  238\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'9606.ENSP00000375892' in communities[index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(communities[index_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1=G.subgraph(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_1: 3409\n",
      "number of edges of sub_1: 457211\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_1:',sub_1.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_1:',sub_1.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 8\n"
     ]
    }
   ],
   "source": [
    "partLouvain_2 = community_louvain.best_partition(sub_1)\n",
    "number_of_communities_2 = max(partLouvain_2.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_2 # 0 is  121\n",
      "The size of community_2 # 1 is  34\n",
      "The size of community_2 # 2 is  487\n",
      "The size of community_2 # 3 is  623\n",
      "The size of community_2 # 4 is  785\n",
      "The size of community_2 # 5 is  167\n",
      "The size of community_2 # 6 is  502\n",
      "The size of community_2 # 7 is  690\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_2 = {} #empty dictionary\n",
    "for i in range(number_of_communities_2):\n",
    "    communities_2[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_2.items():\n",
    "    communities_2[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_2:\n",
    "    print('The size of community_2 #', list(communities_2.keys())[k], 'is ',len(communities_2[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2=partLouvain_2['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2=G.subgraph(communities_2[index_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_2: 623\n",
      "number of edges of sub_2: 35826\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_2:',sub_2.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_2:',sub_2.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 6\n"
     ]
    }
   ],
   "source": [
    "partLouvain_3 = community_louvain.best_partition(sub_2)\n",
    "number_of_communities_3 = max(partLouvain_3.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_3 # 0 is  156\n",
      "The size of community_3 # 1 is  196\n",
      "The size of community_3 # 2 is  11\n",
      "The size of community_3 # 3 is  150\n",
      "The size of community_3 # 4 is  65\n",
      "The size of community_3 # 5 is  45\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_3 = {} #empty dictionary\n",
    "for i in range(number_of_communities_3):\n",
    "    communities_3[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_3.items():\n",
    "    communities_3[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_3:\n",
    "    print('The size of community_3 #', list(communities_3.keys())[k], 'is ',len(communities_3[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3=partLouvain_3['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_3=G.subgraph(communities_3[index_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_3: 65\n",
      "number of edges of sub_3: 1281\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_3:',sub_3.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_3:',sub_3.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_4 = community_louvain.best_partition(sub_3)\n",
    "number_of_communities_4 = max(partLouvain_4.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_4 # 0 is  23\n",
      "The size of community_4 # 1 is  13\n",
      "The size of community_4 # 2 is  19\n",
      "The size of community_4 # 3 is  10\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_4 = {} #empty dictionary\n",
    "for i in range(number_of_communities_4):\n",
    "    communities_4[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_4.items():\n",
    "    communities_4[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_4:\n",
    "    print('The size of community_4 #', list(communities_4.keys())[k], 'is ',len(communities_4[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4=partLouvain_4['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_4=G.subgraph(communities_4[index_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_4: 19\n",
      "number of edges of sub_4: 143\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_4:',sub_4.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_4:',sub_4.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 3\n"
     ]
    }
   ],
   "source": [
    "partLouvain_5 = community_louvain.best_partition(sub_4)\n",
    "number_of_communities_5 = max(partLouvain_5.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_5 # 0 is  7\n",
      "The size of community_5 # 1 is  4\n",
      "The size of community_5 # 2 is  8\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_5 = {} #empty dictionary\n",
    "for i in range(number_of_communities_5):\n",
    "    communities_5[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_5.items():\n",
    "    communities_5[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_5:\n",
    "    print('The size of community_5 #', list(communities_5.keys())[k], 'is ',len(communities_5[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_5=partLouvain_5['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the community containing AKT2 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community is reduced to a manageable size (11) so we can extract the proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interesting proteins related to APK-2 are:\n",
      "ENSP00000375892\n",
      "ENSP00000262719\n",
      "ENSP00000263826\n",
      "ENSP00000354558\n",
      "ENSP00000171887\n",
      "ENSP00000225577\n",
      "ENSP00000308413\n",
      "ENSP00000468280\n"
     ]
    }
   ],
   "source": [
    "print('The interesting proteins related to APK-2 are:')\n",
    "for i in communities_5[index_5]:\n",
    "    pro=i.lstrip('9606.')\n",
    "    print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cluster = {}\n",
    "\n",
    "for key in communities_5.keys():\n",
    "    G_cluster[key] = G0.subgraph(communities_5[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality of nodes in the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_keys(dict):\n",
    "    max_value=max(dict.values())\n",
    "    return [k for k,v in dict.items() if v == max_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_key_value(dict):\n",
    "   key=max_keys(dict)[0]\n",
    "   return dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_cen=nx.degree_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000263826': 1.0,\n",
       " '9606.ENSP00000354558': 1.0,\n",
       " '9606.ENSP00000225577': 1.0,\n",
       " '9606.ENSP00000171887': 1.0,\n",
       " '9606.ENSP00000375892': 1.0,\n",
       " '9606.ENSP00000262719': 1.0,\n",
       " '9606.ENSP00000308413': 0.8571428571428571,\n",
       " '9606.ENSP00000468280': 0.8571428571428571}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen = nx.betweenness_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000263826': 0.007936507936507936,\n",
       " '9606.ENSP00000354558': 0.007936507936507936,\n",
       " '9606.ENSP00000225577': 0.007936507936507936,\n",
       " '9606.ENSP00000171887': 0.007936507936507936,\n",
       " '9606.ENSP00000375892': 0.007936507936507936,\n",
       " '9606.ENSP00000262719': 0.007936507936507936,\n",
       " '9606.ENSP00000308413': 0.0,\n",
       " '9606.ENSP00000468280': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_cen = nx.eigenvector_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000263826': 0.363456285407753,\n",
       " '9606.ENSP00000354558': 0.363456285407753,\n",
       " '9606.ENSP00000225577': 0.363456285407753,\n",
       " '9606.ENSP00000171887': 0.363456285407753,\n",
       " '9606.ENSP00000375892': 0.363456285407753,\n",
       " '9606.ENSP00000262719': 0.363456285407753,\n",
       " '9606.ENSP00000308413': 0.3220226479501,\n",
       " '9606.ENSP00000468280': 0.3220226479501}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_dict={\"Degree cen\":(max_keys(deg_cen),max_key_value(deg_cen)),\"Betweeness cen\":(max_keys(bet_cen),max_key_value(bet_cen)),\"Eigenvector cen\":(max_keys(eig_cen),max_key_value(eig_cen))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Degree cen': (['9606.ENSP00000263826',\n",
       "   '9606.ENSP00000354558',\n",
       "   '9606.ENSP00000225577',\n",
       "   '9606.ENSP00000171887',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000262719'],\n",
       "  1.0),\n",
       " 'Betweeness cen': (['9606.ENSP00000263826',\n",
       "   '9606.ENSP00000354558',\n",
       "   '9606.ENSP00000225577',\n",
       "   '9606.ENSP00000171887',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000262719'],\n",
       "  0.007936507936507936),\n",
       " 'Eigenvector cen': (['9606.ENSP00000263826',\n",
       "   '9606.ENSP00000354558',\n",
       "   '9606.ENSP00000225577',\n",
       "   '9606.ENSP00000171887',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000262719'],\n",
       "  0.363456285407753)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <networkx.classes.graph.Graph at 0x7fe0442576a0>,\n",
       " 1: <networkx.classes.graph.Graph at 0x7fe044257b50>,\n",
       " 2: <networkx.classes.graph.Graph at 0x7fe044257280>}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the communities which have links to the community of the target protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': 25, '02': 44, '12': 25}\n"
     ]
    }
   ],
   "source": [
    "#edges dict with community label as key and (0,1) for edge/no-edge as value\n",
    "edges = {}\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for j in range(i+1,number_of_communities_5):\n",
    "        edges[str(i)+str(j)] = 0\n",
    "\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for node in G_cluster[i].nodes():\n",
    "        for neighbor in G0.neighbors(node):\n",
    "            for j in range(i+1,number_of_communities_5):\n",
    "                if neighbor in communities_5[j]:\n",
    "                    edges[str(i)+str(j)] += 1\n",
    "\n",
    "print(edges) # convention: 'ij' denotes the edge between node(=community) i and node(=community) j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Find the communities which have links to the community of the target protein\n",
    "neighbor_community = []\n",
    "for i in range(number_of_communities_5):\n",
    "    if i < index_5:\n",
    "        if edges[str(i)+str(index_5)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "    if i > index_5:\n",
    "        if edges[str(index_5)+str(i)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "        \n",
    "print(neighbor_community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality of nodes in neighbouring community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "com=G.subgraph(communities_5[1])\n",
    "deg_cen_nei=nx.degree_centrality(com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000379842': 1.0,\n",
       " '9606.ENSP00000344220': 1.0,\n",
       " '9606.ENSP00000340608': 0.6666666666666666,\n",
       " '9606.ENSP00000429022': 0.6666666666666666}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen_nei=nx.betweenness_centrality(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000379842': 0.16666666666666666,\n",
       " '9606.ENSP00000344220': 0.16666666666666666,\n",
       " '9606.ENSP00000340608': 0.0,\n",
       " '9606.ENSP00000429022': 0.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000379842': 0.5573453897277424,\n",
       " '9606.ENSP00000344220': 0.5573453897277424,\n",
       " '9606.ENSP00000340608': 0.43516217270028296,\n",
       " '9606.ENSP00000429022': 0.43516217270028296}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_cen_nei=nx.eigenvector_centrality(com)\n",
    "eig_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9606.ENSP00000429022'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(eig_cen_nei)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
