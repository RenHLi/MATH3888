{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\.conda\\envs\\new_py\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"9606.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 19385\n",
      "number of edges of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of G0:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 19385\n",
      "number of edges of largest connected subgraph of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of target node:  1889\n"
     ]
    }
   ],
   "source": [
    "print(\"degree of target node: \",G0.degree('9606.ENSP00000375892'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree sequence\n",
    "degS=[G.degree()[node] for node in list(G.nodes())]\n",
    "degS.sort()\n",
    "degS=np.array(degS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 7\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partLouvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_1=partLouvain['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  2706\n",
      "The size of community # 1 is  3271\n",
      "The size of community # 2 is  3524\n",
      "The size of community # 3 is  3604\n",
      "The size of community # 4 is  2973\n",
      "The size of community # 5 is  2967\n",
      "The size of community # 6 is  340\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'9606.ENSP00000375892' in communities[index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1=G.subgraph(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_1: 3604\n",
      "number of edges of sub_1: 650722\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_1:',sub_1.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_1:',sub_1.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 6\n"
     ]
    }
   ],
   "source": [
    "partLouvain_2 = community_louvain.best_partition(sub_1)\n",
    "number_of_communities_2 = max(partLouvain_2.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_2 # 0 is  311\n",
      "The size of community_2 # 1 is  603\n",
      "The size of community_2 # 2 is  328\n",
      "The size of community_2 # 3 is  835\n",
      "The size of community_2 # 4 is  497\n",
      "The size of community_2 # 5 is  1030\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_2 = {} #empty dictionary\n",
    "for i in range(number_of_communities_2):\n",
    "    communities_2[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_2.items():\n",
    "    communities_2[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_2:\n",
    "    print('The size of community_2 #', list(communities_2.keys())[k], 'is ',len(communities_2[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2=partLouvain_2['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2=G.subgraph(communities_2[index_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_2: 328\n",
      "number of edges of sub_2: 18637\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_2:',sub_2.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_2:',sub_2.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_3 = community_louvain.best_partition(sub_2)\n",
    "number_of_communities_3 = max(partLouvain_3.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_3 # 0 is  34\n",
      "The size of community_3 # 1 is  88\n",
      "The size of community_3 # 2 is  60\n",
      "The size of community_3 # 3 is  146\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_3 = {} #empty dictionary\n",
    "for i in range(number_of_communities_3):\n",
    "    communities_3[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_3.items():\n",
    "    communities_3[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_3:\n",
    "    print('The size of community_3 #', list(communities_3.keys())[k], 'is ',len(communities_3[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3=partLouvain_3['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_3=G.subgraph(communities_3[index_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_3: 146\n",
      "number of edges of sub_3: 5046\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_3:',sub_3.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_3:',sub_3.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 5\n"
     ]
    }
   ],
   "source": [
    "partLouvain_4 = community_louvain.best_partition(sub_3)\n",
    "number_of_communities_4 = max(partLouvain_4.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_4 # 0 is  44\n",
      "The size of community_4 # 1 is  52\n",
      "The size of community_4 # 2 is  12\n",
      "The size of community_4 # 3 is  18\n",
      "The size of community_4 # 4 is  20\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_4 = {} #empty dictionary\n",
    "for i in range(number_of_communities_4):\n",
    "    communities_4[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_4.items():\n",
    "    communities_4[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_4:\n",
    "    print('The size of community_4 #', list(communities_4.keys())[k], 'is ',len(communities_4[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4=partLouvain_4['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_4=G.subgraph(communities_4[index_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_4: 52\n",
      "number of edges of sub_4: 797\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_4:',sub_4.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_4:',sub_4.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_5 = community_louvain.best_partition(sub_4)\n",
    "number_of_communities_5 = max(partLouvain_5.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_5 # 0 is  21\n",
      "The size of community_5 # 1 is  3\n",
      "The size of community_5 # 2 is  17\n",
      "The size of community_5 # 3 is  11\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_5 = {} #empty dictionary\n",
    "for i in range(number_of_communities_5):\n",
    "    communities_5[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_5.items():\n",
    "    communities_5[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_5:\n",
    "    print('The size of community_5 #', list(communities_5.keys())[k], 'is ',len(communities_5[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_5=partLouvain_5['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interesting proteins related to APK-2 are:\n",
      "ENSP00000385824\n",
      "ENSP00000324806\n",
      "ENSP00000363377\n",
      "ENSP00000354558\n",
      "ENSP00000228872\n",
      "ENSP00000263826\n",
      "ENSP00000375892\n",
      "ENSP00000381070\n",
      "ENSP00000340691\n",
      "ENSP00000280154\n",
      "ENSP00000225577\n"
     ]
    }
   ],
   "source": [
    "print('The interesting proteins related to APK-2 are:')\n",
    "for i in communities_5[index_5]:\n",
    "    pro=i.lstrip('9606.')\n",
    "    print(pro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('new_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365b9593587ed276fd5de7239365279e1225f9b1cb83484bb61ff6345923309a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
