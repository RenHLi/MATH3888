{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the network containing all human proteins on Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"9606.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 19385\n",
      "number of edges of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of G0:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 19385\n",
      "number of edges of largest connected subgraph of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of target node:  1889\n"
     ]
    }
   ],
   "source": [
    "print(\"degree of target node: \",G0.degree('9606.ENSP00000375892'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree sequence\n",
    "degS=[G.degree()[node] for node in list(G.nodes())]\n",
    "degS.sort()\n",
    "degS=np.array(degS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 7\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partLouvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1=partLouvain['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  2649\n",
      "The size of community # 1 is  3299\n",
      "The size of community # 2 is  3605\n",
      "The size of community # 3 is  3644\n",
      "The size of community # 4 is  2028\n",
      "The size of community # 5 is  3219\n",
      "The size of community # 6 is  941\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'9606.ENSP00000375892' in communities[index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(communities[index_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1=G.subgraph(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_1: 3644\n",
      "number of edges of sub_1: 641161\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_1:',sub_1.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_1:',sub_1.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 6\n"
     ]
    }
   ],
   "source": [
    "partLouvain_2 = community_louvain.best_partition(sub_1)\n",
    "number_of_communities_2 = max(partLouvain_2.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_2 # 0 is  1027\n",
      "The size of community_2 # 1 is  254\n",
      "The size of community_2 # 2 is  335\n",
      "The size of community_2 # 3 is  842\n",
      "The size of community_2 # 4 is  657\n",
      "The size of community_2 # 5 is  529\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_2 = {} #empty dictionary\n",
    "for i in range(number_of_communities_2):\n",
    "    communities_2[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_2.items():\n",
    "    communities_2[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_2:\n",
    "    print('The size of community_2 #', list(communities_2.keys())[k], 'is ',len(communities_2[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2=partLouvain_2['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2=G.subgraph(communities_2[index_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_2: 335\n",
      "number of edges of sub_2: 20296\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_2:',sub_2.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_2:',sub_2.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_3 = community_louvain.best_partition(sub_2)\n",
    "number_of_communities_3 = max(partLouvain_3.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_3 # 0 is  74\n",
      "The size of community_3 # 1 is  81\n",
      "The size of community_3 # 2 is  78\n",
      "The size of community_3 # 3 is  102\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_3 = {} #empty dictionary\n",
    "for i in range(number_of_communities_3):\n",
    "    communities_3[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_3.items():\n",
    "    communities_3[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_3:\n",
    "    print('The size of community_3 #', list(communities_3.keys())[k], 'is ',len(communities_3[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3=partLouvain_3['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_3=G.subgraph(communities_3[index_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_3: 102\n",
      "number of edges of sub_3: 2362\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_3:',sub_3.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_3:',sub_3.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_4 = community_louvain.best_partition(sub_3)\n",
    "number_of_communities_4 = max(partLouvain_4.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_4 # 0 is  38\n",
      "The size of community_4 # 1 is  18\n",
      "The size of community_4 # 2 is  38\n",
      "The size of community_4 # 3 is  8\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_4 = {} #empty dictionary\n",
    "for i in range(number_of_communities_4):\n",
    "    communities_4[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_4.items():\n",
    "    communities_4[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_4:\n",
    "    print('The size of community_4 #', list(communities_4.keys())[k], 'is ',len(communities_4[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4=partLouvain_4['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_4=G.subgraph(communities_4[index_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_4: 38\n",
      "number of edges of sub_4: 497\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_4:',sub_4.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_4:',sub_4.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 3\n"
     ]
    }
   ],
   "source": [
    "partLouvain_5 = community_louvain.best_partition(sub_4)\n",
    "number_of_communities_5 = max(partLouvain_5.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_5 # 0 is  14\n",
      "The size of community_5 # 1 is  14\n",
      "The size of community_5 # 2 is  10\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_5 = {} #empty dictionary\n",
    "for i in range(number_of_communities_5):\n",
    "    communities_5[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_5.items():\n",
    "    communities_5[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_5:\n",
    "    print('The size of community_5 #', list(communities_5.keys())[k], 'is ',len(communities_5[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_5=partLouvain_5['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the community containing AKT2 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community is reduced to a manageable size (11) so we can extract the proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interesting proteins related to APK-2 are:\n",
      "ENSP00000354558\n",
      "ENSP00000225577\n",
      "ENSP00000361021\n",
      "ENSP00000451828\n",
      "ENSP00000367830\n",
      "ENSP00000339577\n",
      "ENSP00000263826\n",
      "ENSP00000251849\n",
      "ENSP00000344220\n",
      "ENSP00000345629\n",
      "ENSP00000375711\n",
      "ENSP00000340691\n",
      "ENSP00000201979\n",
      "ENSP00000375892\n"
     ]
    }
   ],
   "source": [
    "print('The interesting proteins related to APK-2 are:')\n",
    "for i in communities_5[index_5]:\n",
    "    pro=i.lstrip('9606.')\n",
    "    print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cluster = {}\n",
    "\n",
    "for key in communities_5.keys():\n",
    "    G_cluster[key] = G0.subgraph(communities_5[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <networkx.classes.graph.Graph at 0x186ec4c6710>,\n",
       " 1: <networkx.classes.graph.Graph at 0x186ea587880>,\n",
       " 2: <networkx.classes.graph.Graph at 0x186e9abc1f0>}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the communities which have links to the community of the target protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': 142, '02': 89, '12': 78}\n"
     ]
    }
   ],
   "source": [
    "#edges dict with community label as key and (0,1) for edge/no-edge as value\n",
    "edges = {}\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for j in range(i+1,number_of_communities_5):\n",
    "        edges[str(i)+str(j)] = 0\n",
    "\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for node in G_cluster[i].nodes():\n",
    "        for neighbor in G0.neighbors(node):\n",
    "            for j in range(i+1,number_of_communities_5):\n",
    "                if neighbor in communities_5[j]:\n",
    "                    edges[str(i)+str(j)] += 1\n",
    "\n",
    "print(edges) # convention: 'ij' denotes the edge between node(=community) i and node(=community) j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n"
     ]
    }
   ],
   "source": [
    "# Find the communities which have links to the community of the target protein\n",
    "neighbor_community = []\n",
    "for i in range(number_of_communities_5):\n",
    "    if i < index_5:\n",
    "        if edges[str(i)+str(index_5)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "    if i > index_5:\n",
    "        if edges[str(index_5)+str(i)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "        \n",
    "print(neighbor_community)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('new_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365b9593587ed276fd5de7239365279e1225f9b1cb83484bb61ff6345923309a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
