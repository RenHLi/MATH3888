{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lihao\\.conda\\envs\\new_py\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the network containing all human proteins on Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"9606.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 19385\n",
      "number of edges of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of G0:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 19385\n",
      "number of edges of largest connected subgraph of G0: 5969249\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of target node:  1889\n"
     ]
    }
   ],
   "source": [
    "print(\"degree of target node: \",G0.degree('9606.ENSP00000375892'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degree sequence\n",
    "degS=[G.degree()[node] for node in list(G.nodes())]\n",
    "degS.sort()\n",
    "degS=np.array(degS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 7\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(partLouvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1=partLouvain['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  3992\n",
      "The size of community # 1 is  3031\n",
      "The size of community # 2 is  2530\n",
      "The size of community # 3 is  255\n",
      "The size of community # 4 is  3894\n",
      "The size of community # 5 is  2316\n",
      "The size of community # 6 is  3367\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'9606.ENSP00000375892' in communities[index_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(communities[index_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_1=G.subgraph(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_1: 3894\n",
      "number of edges of sub_1: 644093\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_1:',sub_1.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_1:',sub_1.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 6\n"
     ]
    }
   ],
   "source": [
    "partLouvain_2 = community_louvain.best_partition(sub_1)\n",
    "number_of_communities_2 = max(partLouvain_2.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_2 # 0 is  900\n",
      "The size of community_2 # 1 is  1078\n",
      "The size of community_2 # 2 is  356\n",
      "The size of community_2 # 3 is  725\n",
      "The size of community_2 # 4 is  297\n",
      "The size of community_2 # 5 is  538\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_2 = {} #empty dictionary\n",
    "for i in range(number_of_communities_2):\n",
    "    communities_2[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_2.items():\n",
    "    communities_2[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_2:\n",
    "    print('The size of community_2 #', list(communities_2.keys())[k], 'is ',len(communities_2[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2=partLouvain_2['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_2=G.subgraph(communities_2[index_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_2: 297\n",
      "number of edges of sub_2: 17565\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_2:',sub_2.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_2:',sub_2.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 6\n"
     ]
    }
   ],
   "source": [
    "partLouvain_3 = community_louvain.best_partition(sub_2)\n",
    "number_of_communities_3 = max(partLouvain_3.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_3 # 0 is  16\n",
      "The size of community_3 # 1 is  25\n",
      "The size of community_3 # 2 is  89\n",
      "The size of community_3 # 3 is  73\n",
      "The size of community_3 # 4 is  61\n",
      "The size of community_3 # 5 is  33\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_3 = {} #empty dictionary\n",
    "for i in range(number_of_communities_3):\n",
    "    communities_3[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_3.items():\n",
    "    communities_3[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_3:\n",
    "    print('The size of community_3 #', list(communities_3.keys())[k], 'is ',len(communities_3[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3=partLouvain_3['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_3=G.subgraph(communities_3[index_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_3: 61\n",
      "number of edges of sub_3: 1102\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_3:',sub_3.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_3:',sub_3.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 4\n"
     ]
    }
   ],
   "source": [
    "partLouvain_4 = community_louvain.best_partition(sub_3)\n",
    "number_of_communities_4 = max(partLouvain_4.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_4 # 0 is  7\n",
      "The size of community_4 # 1 is  23\n",
      "The size of community_4 # 2 is  18\n",
      "The size of community_4 # 3 is  13\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_4 = {} #empty dictionary\n",
    "for i in range(number_of_communities_4):\n",
    "    communities_4[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_4.items():\n",
    "    communities_4[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_4:\n",
    "    print('The size of community_4 #', list(communities_4.keys())[k], 'is ',len(communities_4[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4=partLouvain_4['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the subgraph containing AKT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_4=G.subgraph(communities_4[index_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of sub_4: 18\n",
      "number of edges of sub_4: 126\n"
     ]
    }
   ],
   "source": [
    "#number of nodes of network\n",
    "print('number of nodes of sub_4:',sub_4.number_of_nodes())\n",
    "\n",
    "#number of edges of network\n",
    "print('number of edges of sub_4:',sub_4.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 2\n"
     ]
    }
   ],
   "source": [
    "partLouvain_5 = community_louvain.best_partition(sub_4)\n",
    "number_of_communities_5 = max(partLouvain_5.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community_5 # 0 is  5\n",
      "The size of community_5 # 1 is  13\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities_5 = {} #empty dictionary\n",
    "for i in range(number_of_communities_5):\n",
    "    communities_5[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain_5.items():\n",
    "    communities_5[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities_5:\n",
    "    print('The size of community_5 #', list(communities_5.keys())[k], 'is ',len(communities_5[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_5=partLouvain_5['9606.ENSP00000375892']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of the community containing AKT2 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community is reduced to a manageable size (11) so we can extract the proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interesting proteins related to APK-2 are:\n",
      "ENSP00000367830\n",
      "ENSP00000375892\n",
      "ENSP00000303830\n",
      "ENSP00000344220\n",
      "ENSP00000263915\n"
     ]
    }
   ],
   "source": [
    "print('The interesting proteins related to APK-2 are:')\n",
    "for i in communities_5[index_5]:\n",
    "    pro=i.lstrip('9606.')\n",
    "    print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_cluster = {}\n",
    "\n",
    "for key in communities_5.keys():\n",
    "    G_cluster[key] = G0.subgraph(communities_5[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality of nodes in the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_keys(dict):\n",
    "    max_value=max(dict.values())\n",
    "    return [k for k,v in dict.items() if v == max_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_key_value(dict):\n",
    "   key=max_keys(dict)[0]\n",
    "   return dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_cen=nx.degree_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000367830': 1.0,\n",
       " '9606.ENSP00000375892': 1.0,\n",
       " '9606.ENSP00000303830': 1.0,\n",
       " '9606.ENSP00000344220': 1.0,\n",
       " '9606.ENSP00000263915': 1.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen = nx.betweenness_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000367830': 0.0,\n",
       " '9606.ENSP00000375892': 0.0,\n",
       " '9606.ENSP00000303830': 0.0,\n",
       " '9606.ENSP00000344220': 0.0,\n",
       " '9606.ENSP00000263915': 0.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_cen = nx.eigenvector_centrality(G_cluster[index_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000367830': 0.447213595499958,\n",
       " '9606.ENSP00000375892': 0.447213595499958,\n",
       " '9606.ENSP00000303830': 0.447213595499958,\n",
       " '9606.ENSP00000344220': 0.447213595499958,\n",
       " '9606.ENSP00000263915': 0.447213595499958}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_cen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_dict={\"Degree cen\":(max_keys(deg_cen),max_key_value(deg_cen)),\"Betweeness cen\":(max_keys(bet_cen),max_key_value(bet_cen)),\"Eigenvector cen\":(max_keys(eig_cen),max_key_value(eig_cen))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Degree cen': (['9606.ENSP00000367830',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000303830',\n",
       "   '9606.ENSP00000344220',\n",
       "   '9606.ENSP00000263915'],\n",
       "  1.0),\n",
       " 'Betweeness cen': (['9606.ENSP00000367830',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000303830',\n",
       "   '9606.ENSP00000344220',\n",
       "   '9606.ENSP00000263915'],\n",
       "  0.0),\n",
       " 'Eigenvector cen': (['9606.ENSP00000367830',\n",
       "   '9606.ENSP00000375892',\n",
       "   '9606.ENSP00000303830',\n",
       "   '9606.ENSP00000344220',\n",
       "   '9606.ENSP00000263915'],\n",
       "  0.447213595499958)}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <networkx.classes.graph.Graph at 0x1b6a7807a90>,\n",
       " 1: <networkx.classes.graph.Graph at 0x1b6a7805960>}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the communities which have links to the community of the target protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': 52}\n"
     ]
    }
   ],
   "source": [
    "#edges dict with community label as key and (0,1) for edge/no-edge as value\n",
    "edges = {}\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for j in range(i+1,number_of_communities_5):\n",
    "        edges[str(i)+str(j)] = 0\n",
    "\n",
    "for i in range(number_of_communities_5-1):\n",
    "    for node in G_cluster[i].nodes():\n",
    "        for neighbor in G0.neighbors(node):\n",
    "            for j in range(i+1,number_of_communities_5):\n",
    "                if neighbor in communities_5[j]:\n",
    "                    edges[str(i)+str(j)] += 1\n",
    "\n",
    "print(edges) # convention: 'ij' denotes the edge between node(=community) i and node(=community) j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Find the communities which have links to the community of the target protein\n",
    "neighbor_community = []\n",
    "for i in range(number_of_communities_5):\n",
    "    if i < index_5:\n",
    "        if edges[str(i)+str(index_5)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "    if i > index_5:\n",
    "        if edges[str(index_5)+str(i)] != 0:\n",
    "            neighbor_community.append(i)\n",
    "        \n",
    "print(neighbor_community)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrality of nodes in neighbouring community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "com=G.subgraph(communities_5[1])\n",
    "deg_cen_nei=nx.degree_centrality(com)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000378217': 0.75,\n",
       " '9606.ENSP00000262741': 0.8333333333333333,\n",
       " '9606.ENSP00000222254': 0.8333333333333333,\n",
       " '9606.ENSP00000480059': 0.5833333333333333,\n",
       " '9606.ENSP00000366563': 0.9166666666666666,\n",
       " '9606.ENSP00000352121': 1.0,\n",
       " '9606.ENSP00000439913': 0.5833333333333333,\n",
       " '9606.ENSP00000215912': 0.41666666666666663,\n",
       " '9606.ENSP00000289153': 1.0,\n",
       " '9606.ENSP00000361202': 0.9166666666666666,\n",
       " '9606.ENSP00000263967': 1.0,\n",
       " '9606.ENSP00000268035': 0.9166666666666666,\n",
       " '9606.ENSP00000304895': 0.9166666666666666}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cen_nei=nx.betweenness_centrality(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000378217': 0.0,\n",
       " '9606.ENSP00000262741': 0.01515151515151515,\n",
       " '9606.ENSP00000222254': 0.01515151515151515,\n",
       " '9606.ENSP00000480059': 0.0,\n",
       " '9606.ENSP00000366563': 0.01515151515151515,\n",
       " '9606.ENSP00000352121': 0.0404040404040404,\n",
       " '9606.ENSP00000439913': 0.0,\n",
       " '9606.ENSP00000215912': 0.0,\n",
       " '9606.ENSP00000289153': 0.0404040404040404,\n",
       " '9606.ENSP00000361202': 0.01515151515151515,\n",
       " '9606.ENSP00000263967': 0.0404040404040404,\n",
       " '9606.ENSP00000268035': 0.01515151515151515,\n",
       " '9606.ENSP00000304895': 0.01515151515151515}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bet_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9606.ENSP00000378217': 0.2650085582921057,\n",
       " '9606.ENSP00000262741': 0.2780732558041615,\n",
       " '9606.ENSP00000222254': 0.2780732558041615,\n",
       " '9606.ENSP00000480059': 0.2106812492294767,\n",
       " '9606.ENSP00000366563': 0.30250631490069146,\n",
       " '9606.ENSP00000352121': 0.3155710124127473,\n",
       " '9606.ENSP00000439913': 0.2106812492294767,\n",
       " '9606.ENSP00000215912': 0.14680715734015237,\n",
       " '9606.ENSP00000289153': 0.3155710124127473,\n",
       " '9606.ENSP00000361202': 0.30250631490069146,\n",
       " '9606.ENSP00000263967': 0.3155710124127473,\n",
       " '9606.ENSP00000268035': 0.30250631490069146,\n",
       " '9606.ENSP00000304895': 0.30250631490069146}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_cen_nei=nx.eigenvector_centrality(com)\n",
    "eig_cen_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9606.ENSP00000480059'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(eig_cen_nei)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('new_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365b9593587ed276fd5de7239365279e1225f9b1cb83484bb61ff6345923309a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
