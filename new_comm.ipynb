{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import random as rn\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the network\n",
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the edges below our chosen threshold\n",
    "threshold_score = 400\n",
    "for edge in G0.edges: \n",
    "    weight = list(G0.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G0.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 6394\n",
      "number of edges of G0: 282074\n",
      "Is the full G0 connected? False\n",
      "How many connected subgraphs are there? 282\n",
      "number of nodes of largest connected subgraph of G0: 6113\n",
      "number of edges of largest connected subgraph of G0: 282074\n"
     ]
    }
   ],
   "source": [
    "# some basic information:\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "print('number of edges of G0:',G0.number_of_edges())\n",
    "print('Is the full G0 connected?',nx.connected.is_connected(G0))\n",
    "print('How many connected subgraphs are there?',nx.connected.number_connected_components(G0))\n",
    "# largest subcomponent\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('number of nodes of largest connected subgraph of G0:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove essential nodes\n",
    "ess=pd.read_csv(\"essential_pro.csv\",header=None)\n",
    "ess_pro=pd.Series.to_list(ess[1])\n",
    "for i in range(len(ess_pro)):\n",
    "    ess_pro[i]='4932.'+ess_pro[i]\n",
    "G0.remove_nodes_from(ess_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 5098\n",
      "number of edges of G0: 137012\n"
     ]
    }
   ],
   "source": [
    "# some more basic information:\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "print('number of edges of G0:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the nodes most closely connected to our protein of interest\n",
    "nodes = nx.shortest_path(G0,'4932.YKL126W').keys()\n",
    "G=G0.subgraph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G: 4827\n",
      "number of edges of G: 137012\n"
     ]
    }
   ],
   "source": [
    "# some basic information about this subgraph\n",
    "print('number of nodes of G:',G.number_of_nodes())\n",
    "print('number of edges of G:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define a parent class of network\n",
    "class Network:\n",
    "    R = 50\n",
    "    N = 10\n",
    "\n",
    "    def __init__(self, graph, homologue, partition_method, centrality_method):\n",
    "        self.graph = graph\n",
    "        self.homologue = homologue\n",
    "        self.partition_method = partition_method\n",
    "        self.partitions = []\n",
    "        self.homologue_communities = []\n",
    "        # TODO: self.adjacent_communtieis = []\n",
    "        self.centrality_method = centrality_method\n",
    "        self.central_nodes = [] # { encoding : centrality }\n",
    "\n",
    "    def get_partition(self, s):\n",
    "        if self.partition_method == \"louvain\":\n",
    "            return nx_comm.louvain_communities(self.graph, resolution=Network.R, seed=s)\n",
    "        # ...\n",
    "\n",
    "    def find_partitions_robust(self):\n",
    "        self.partitions = [self.get_partition(rn.seed(i)) for i in range(Network.N)]\n",
    "        # TODO: retrieve self.homologue_communities\n",
    " \n",
    "    def get_central_nodes(self, i):\n",
    "        if self.centrality_method == \"degree\":\n",
    "            return nx.degree_centrality(self.homologue_communities[i])\n",
    "        elif self.centrality_method == \"betweenness\":\n",
    "            return nx.betweenness_centrality(self.homologue_communities[i])\n",
    "        elif self.centrality_method == \"eigenvector\":\n",
    "            return nx.eigenvector_centrality(self.homologue_communities[i])\n",
    "\n",
    "    def get_central_nodes_robust(self):\n",
    "        self.central_nodes = [self.get_central_nodes(i) for i in range(Network.N)]\n",
    "        # TODO: decide how to cross reference the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some information about the partition of the strongly connected graph\n",
    "partLouvain = community_louvain.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 9\n",
      "0.5435814018014984\n"
     ]
    }
   ],
   "source": [
    "# some information about the subgraph's partition\n",
    "print('# of partitions for Louvain modularity =',max(partLouvain.values())+1)\n",
    "print(community_louvain.modularity(partLouvain, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels\n",
    "# and the values will be a list of nodes in that community.\n",
    "def community_collector(comm):\n",
    "    number_of_communities = max(comm.values())+1\n",
    "    communities = {} #empty dictionary\n",
    "    for i in range(number_of_communities):\n",
    "        communities[i] = [] #create an empty list for each community\n",
    "\n",
    "    for name, community in comm.items():\n",
    "        communities[community].append(name) \n",
    "    return communities\n",
    "\n",
    "communities = community_collector(partLouvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  645\n",
      "The size of community # 1 is  273\n",
      "The size of community # 2 is  346\n",
      "The size of community # 3 is  308\n",
      "The size of community # 4 is  400\n",
      "The size of community # 5 is  1135\n",
      "The size of community # 6 is  891\n",
      "The size of community # 7 is  809\n",
      "The size of community # 8 is  20\n"
     ]
    }
   ],
   "source": [
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX\n",
    "# would be. In your own investigations you can decide what is more useful.\n",
    "\n",
    "# Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1=partLouvain['4932.YKL126W']\n",
    "sub_1=G.subgraph(communities[index_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_1.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_keys(dict):\n",
    "    max_value=max(dict.values())\n",
    "    return [k for k,v in dict.items() if v == max_value]\n",
    "\n",
    "def max_key_value(dict):\n",
    "   key=max_keys(dict)[0]\n",
    "   return dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_cen = nx.degree_centrality(sub_1)\n",
    "bet_cen = nx.betweenness_centrality(sub_1)\n",
    "eig_cen = nx.eigenvector_centrality(sub_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Degree cen': (['4932.YHR030C'], 0.14285714285714285), 'Betweeness cen': (['4932.YHR030C'], 0.01960049310913199), 'Eigenvector cen': (['4932.YHR030C'], 0.13661182974703667)}\n"
     ]
    }
   ],
   "source": [
    "central_dict={\n",
    "    \"Degree cen\"        :   (max_keys(deg_cen),max_key_value(deg_cen)),\n",
    "    \"Betweeness cen\"    :   (max_keys(bet_cen),max_key_value(bet_cen)),\n",
    "    \"Eigenvector cen\"   :   (max_keys(eig_cen),max_key_value(eig_cen))\n",
    "}\n",
    "print(central_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  9\n",
      "The size of community # 1 is  6\n",
      "The size of community # 2 is  12\n",
      "The size of community # 3 is  36\n",
      "The size of community # 4 is  7\n",
      "The size of community # 5 is  9\n",
      "The size of community # 6 is  36\n",
      "The size of community # 7 is  18\n",
      "The size of community # 8 is  4\n",
      "The size of community # 9 is  18\n",
      "The size of community # 10 is  5\n",
      "The size of community # 11 is  13\n",
      "The size of community # 12 is  94\n",
      "The size of community # 13 is  32\n",
      "The size of community # 14 is  2\n",
      "The size of community # 15 is  7\n",
      "The size of community # 16 is  65\n",
      "The size of community # 17 is  18\n",
      "The size of community # 18 is  2\n",
      "The size of community # 19 is  36\n",
      "The size of community # 20 is  21\n",
      "The size of community # 21 is  9\n",
      "The size of community # 22 is  6\n",
      "The size of community # 23 is  4\n",
      "The size of community # 24 is  35\n",
      "The size of community # 25 is  5\n",
      "The size of community # 26 is  6\n",
      "The size of community # 27 is  6\n",
      "The size of community # 28 is  3\n",
      "The size of community # 29 is  7\n",
      "The size of community # 30 is  50\n",
      "The size of community # 31 is  319\n",
      "The size of community # 32 is  2\n",
      "The size of community # 33 is  11\n",
      "The size of community # 34 is  2\n",
      "The size of community # 35 is  2\n",
      "The size of community # 36 is  482\n",
      "The size of community # 37 is  69\n",
      "The size of community # 38 is  100\n",
      "The size of community # 39 is  4\n",
      "The size of community # 40 is  416\n",
      "The size of community # 41 is  360\n",
      "The size of community # 42 is  8\n",
      "The size of community # 43 is  82\n",
      "The size of community # 44 is  2\n",
      "The size of community # 45 is  3\n",
      "The size of community # 46 is  2\n",
      "The size of community # 47 is  34\n",
      "The size of community # 48 is  85\n",
      "The size of community # 49 is  8\n",
      "The size of community # 50 is  361\n",
      "The size of community # 51 is  31\n",
      "The size of community # 52 is  7\n",
      "The size of community # 53 is  8\n",
      "The size of community # 54 is  5\n",
      "The size of community # 55 is  71\n",
      "The size of community # 56 is  6\n",
      "The size of community # 57 is  4\n",
      "The size of community # 58 is  8\n",
      "The size of community # 59 is  78\n",
      "The size of community # 60 is  13\n",
      "The size of community # 61 is  27\n",
      "The size of community # 62 is  4\n",
      "The size of community # 63 is  6\n",
      "The size of community # 64 is  3\n",
      "The size of community # 65 is  2\n",
      "The size of community # 66 is  23\n",
      "The size of community # 67 is  16\n",
      "The size of community # 68 is  52\n",
      "The size of community # 69 is  291\n",
      "The size of community # 70 is  41\n",
      "The size of community # 71 is  8\n",
      "The size of community # 72 is  3\n",
      "The size of community # 73 is  180\n",
      "The size of community # 74 is  24\n",
      "The size of community # 75 is  620\n",
      "The size of community # 76 is  6\n",
      "The size of community # 77 is  18\n",
      "The size of community # 78 is  4\n",
      "The size of community # 79 is  74\n",
      "The size of community # 80 is  6\n",
      "The size of community # 81 is  3\n",
      "The size of community # 82 is  6\n",
      "The size of community # 83 is  3\n",
      "The size of community # 84 is  6\n",
      "The size of community # 85 is  78\n",
      "The size of community # 86 is  11\n",
      "The size of community # 87 is  30\n",
      "The size of community # 88 is  9\n",
      "The size of community # 89 is  50\n",
      "The size of community # 90 is  18\n",
      "The size of community # 91 is  41\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e4ab13a2580d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunity_louvain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition_at_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdendrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'4932.YKL126W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommunities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 40"
     ]
    }
   ],
   "source": [
    "dendrogram = community_louvain.generate_dendrogram(G)\n",
    "\n",
    "# Let's construct a dictionary object called 'd_communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "d_communities = community_collector(community_louvain.partition_at_level(dendrogram, 0))\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in d_communities:\n",
    "    print('The size of community #', list(d_communities.keys())[k], 'is ',len(d_communities[k]))\n",
    "\n",
    "ind = community_louvain.partition_at_level(dendrogram, 0)['4932.YKL126W']\n",
    "len(communities[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(community_louvain.partition_at_level(dendrogram, 0)['4932.YKL126W'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx.algorithms.community' has no attribute 'louvain_communities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-88f59706190a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnxLouvain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx_comm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlouvain_communities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxLouvain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnxLouvain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print('Community', i, 'has', len(nxLouvain[i]), 'nodes.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx.algorithms.community' has no attribute 'louvain_communities'"
     ]
    }
   ],
   "source": [
    "nxLouvain=nx_comm.louvain_communities(G, resolution=5)\n",
    "print(len(nxLouvain))\n",
    "idx='x'\n",
    "for i in range(len(nxLouvain)):\n",
    "    if '4932.YKL126W' in nxLouvain[i]: idx=i\n",
    "print(idx)\n",
    "print(len(nxLouvain[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1=G.subgraph(nxLouvain[idx])\n",
    "deg_cen=nx.degree_centrality(sub1)\n",
    "bet_cen = nx.betweenness_centrality(sub1)\n",
    "eig_cen = nx.eigenvector_centrality(sub1)\n",
    "print(sorted(deg_cen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Degree cen': (['4932.YHR030C'], 0.14285714285714285), 'Betweeness cen': (['4932.YHR030C'], 0.01960049310913199), 'Eigenvector cen': (['4932.YHR030C'], 0.13661182974703667)}\n"
     ]
    }
   ],
   "source": [
    "central_dict={\"Degree cen\":(max_keys(deg_cen),max_key_value(deg_cen)),\n",
    "\"Betweeness cen\":(max_keys(bet_cen),max_key_value(bet_cen)),\"Eigenvector cen\":(max_keys(eig_cen),max_key_value(eig_cen))}\n",
    "print(central_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('4932.YHR030C', 0.14285714285714285), ('4932.YDL192W', 0.13051146384479717), ('4932.YML001W', 0.12698412698412698), ('4932.YBL016W', 0.12257495590828923), ('4932.YNL098C', 0.12081128747795414)]\n",
      "\n",
      "[('4932.YHR030C', 0.01960049310913199), ('4932.YML001W', 0.01686450288370687), ('4932.YBR164C', 0.016137941371008116), ('4932.YNL098C', 0.015564708363344846), ('4932.YDR388W', 0.015217349939506165)]\n",
      "\n",
      "[('4932.YHR030C', 0.13661182974703667), ('4932.YDL192W', 0.12609436063021143), ('4932.YBL016W', 0.12280312041458243), ('4932.YLR113W', 0.12264986267517693), ('4932.YER031C', 0.1172542500101329)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(deg_cen.items(), key=lambda item: item[1],reverse=True)[0:5])\n",
    "print()\n",
    "print(sorted(bet_cen.items(), key=lambda item: item[1],reverse=True)[0:5])\n",
    "print()\n",
    "print(sorted(eig_cen.items(), key=lambda item: item[1],reverse=True)[0:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
