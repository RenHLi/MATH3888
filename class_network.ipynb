{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import random as rn\n",
    "from heapq import nlargest\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_score = 400\n",
    "for edge in G0.edges: \n",
    "    weight = list(G0.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G0.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 6394\n",
      "number of edges of G0: 282074\n"
     ]
    }
   ],
   "source": [
    "# some basic information\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "print('number of edges of G0:',G0.number_of_edges())\n",
    "print('Is the full G0 connected?',nx.connected.is_connected(G0))\n",
    "print('How many connected subgraphs are there?',nx.connected.number_connected_components(G0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 6113\n",
      "number of edges of largest connected subgraph of G0: 282074\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the essential nodes from G0\n",
    "ess=pd.read_csv(\"essential_pro.csv\",header=None)\n",
    "ess_pro=pd.Series.to_list(ess[1])\n",
    "for i in range(len(ess_pro)):\n",
    "    ess_pro[i]='4932.'+ess_pro[i]\n",
    "G0.remove_nodes_from(ess_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 5098\n",
      "number of edges of G0: 137012\n"
     ]
    }
   ],
   "source": [
    "# new information\n",
    "print('number of nodes of G0 without essential nodes:',G0.number_of_nodes())\n",
    "print('number of edges of G0 without essential nodes:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow our selection to the proteins connected to ours\n",
    "nodes = nx.shortest_path(G0,'4932.YKL126W').keys()\n",
    "G=G0.subgraph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G: 4827\n",
      "number of edges of G: 137012\n"
     ]
    }
   ],
   "source": [
    "# some basic information #3\n",
    "print('number of nodes of G:',G.number_of_nodes())\n",
    "print('number of edges of G:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define a parent class of network\n",
    "class Network:\n",
    "    R = 50\n",
    "    N = 10\n",
    "\n",
    "    def __init__(self, graph, homologue,\n",
    "     #centrality_method,\n",
    "      partition_method=\"louvain\"):\n",
    "        self.graph = graph\n",
    "        self.homologue = homologue\n",
    "        self.partition_method = partition_method\n",
    "        self.partitions = []\n",
    "        self.communities = []\n",
    "        self.homologue_communities = []\n",
    "        # TODO: self.adjacent_communtieis = []\n",
    "        #self.centrality_method = centrality_method\n",
    "        self.central_nodes = [] # { encoding : centrality }\n",
    "        self.important_nodes={}\n",
    "        self.find_partions_robust()\n",
    "        self.find_homologue_communities()\n",
    "        self.get_central_nodes_robust()\n",
    "        self.get_important_nodes()\n",
    "        # self.find_communities()\n",
    "\n",
    "    def get_partition(self, s):\n",
    "        if self.partition_method == \"louvain\":\n",
    "            return nx_comm.louvain_communities(self.graph, resolution=Network.R, seed=s)\n",
    "        # ...\n",
    "    # def community_collector(self,comm):\n",
    "    #     number_of_communities = max(comm.values())+1\n",
    "    #     communities = {} #empty dictionary\n",
    "    #     for i in range(number_of_communities):\n",
    "    #         communities[i] = [] #create an empty list for each community\n",
    "\n",
    "    #     for name, community in comm.items():\n",
    "    #         communities[community].append(name) \n",
    "    #     return communities\n",
    "\n",
    "    def find_partions_robust(self):\n",
    "        for i in range(Network.N):\n",
    "            self.partitions.append(self.get_partition(i))\n",
    "        # TODO: retrieve self.homologue_communities\n",
    "\n",
    "    # def find_communities(self):\n",
    "    #     for i in self.partitions:\n",
    "    #         self.communities.append(self.community_collector(i))\n",
    "        \n",
    "    \n",
    "    def find_homologue_communities(self):\n",
    "        \n",
    "        for part in (self.partitions):\n",
    "            #print('Community', i, 'has', len(nxLouvain[i]), 'nodes.')\n",
    "            idx='x'\n",
    "            for i in range(len(part)):\n",
    "                if self.homologue in part[i]:\n",
    "                    idx=i\n",
    "                    break\n",
    "\n",
    "            sub1=G.subgraph(part[idx])\n",
    "            self.homologue_communities.append(sub1)\n",
    "        # for i in range(len(self.communities)):\n",
    "\n",
    "        #     idx=self.partitions[i][self.homologue]\n",
    "        #     a=self.graph.subgraph(self.communities[i][idx])\n",
    "        #     self.homologue_communities.append(a)\n",
    "\n",
    "\n",
    "    def central_nodes_finder(self, i):\n",
    "        \n",
    "        a= nx.degree_centrality(self.homologue_communities[i])\n",
    "        b= nx.betweenness_centrality(self.homologue_communities[i])\n",
    "        c= nx.eigenvector_centrality(self.homologue_communities[i])\n",
    "        a5=nlargest(5, a, key = a.get)\n",
    "        b5=nlargest(5, b, key = b.get)\n",
    "        c5=nlargest(5, c, key = c.get)\n",
    "        c_nodes={*a,*b,*c}\n",
    "        return list(c_nodes)\n",
    "\n",
    "    def get_central_nodes_robust(self):\n",
    "        for i in range(Network.N):\n",
    "            self.central_nodes.append(self.central_nodes_finder(i))\n",
    "        # TODO: decide how to cross reference the results\n",
    "\n",
    "    def get_important_nodes(self):\n",
    "        # flatten the central nodes list\n",
    "        flat_central_nodes = [y for x in self.central_nodes for y in x]\n",
    "        for node in flat_central_nodes:\n",
    "            if node not in self.important_nodes:\n",
    "                self.important_nodes[node]=flat_central_nodes.count(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein=Network(G,homologue='4932.YKL126W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4932.YIL105C': 5,\n",
       " '4932.YMR068W': 8,\n",
       " '4932.YMR104C': 8,\n",
       " '4932.YKL126W': 10,\n",
       " '4932.YBR270C': 8,\n",
       " '4932.YJL058C': 8,\n",
       " '4932.YNL047C': 3,\n",
       " '4932.YMR102C': 1,\n",
       " '4932.YKL128C': 1,\n",
       " '4932.YMR103C': 1,\n",
       " '4932.YMR101C': 1,\n",
       " '4932.YBR013C': 1,\n",
       " '4932.YDR466W': 1,\n",
       " '4932.YBR028C': 1,\n",
       " '4932.YDL037C': 1,\n",
       " '4932.YDL039C': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein.important_nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
