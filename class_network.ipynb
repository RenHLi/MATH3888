{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import random as rn\n",
    "from heapq import nlargest\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 32}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import community as community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_score = 700\n",
    "for edge in G0.edges: \n",
    "    weight = list(G0.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G0.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0: 6394\n",
      "number of edges of G0: 120009\n",
      "Is the full G0 connected? False\n",
      "How many connected subgraphs are there? 441\n"
     ]
    }
   ],
   "source": [
    "# some basic information\n",
    "print('number of nodes of G0:',G0.number_of_nodes())\n",
    "print('number of edges of G0:',G0.number_of_edges())\n",
    "print('Is the full G0 connected?',nx.connected.is_connected(G0))\n",
    "print('How many connected subgraphs are there?',nx.connected.number_connected_components(G0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type <class 'set'>\n",
      "number of nodes of largest connected subgraph of G: 5932\n",
      "number of edges of largest connected subgraph of G0: 119977\n"
     ]
    }
   ],
   "source": [
    "#get the largest component\n",
    "largest_cc = max(nx.connected_components(G0),key=len)\n",
    "G = G0.subgraph(largest_cc)\n",
    "print('Type',type(largest_cc))\n",
    "print('number of nodes of largest connected subgraph of G:',G.number_of_nodes())\n",
    "print('number of edges of largest connected subgraph of G0:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the essential nodes from G0\n",
    "ess=pd.read_csv(\"essential_pro.csv\",header=None)\n",
    "ess_pro=pd.Series.to_list(ess[1])\n",
    "for i in range(len(ess_pro)):\n",
    "    ess_pro[i]='4932.'+ess_pro[i]\n",
    "G0.remove_nodes_from(ess_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G0 without essential nodes: 5098\n",
      "number of edges of G0 without essential nodes: 53343\n"
     ]
    }
   ],
   "source": [
    "# new information 53343\n",
    "print('number of nodes of G0 without essential nodes:',G0.number_of_nodes())\n",
    "print('number of edges of G0 without essential nodes:',G0.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow our selection to the proteins connected to ours\n",
    "nodes = nx.shortest_path(G0,'4932.YKL126W').keys()\n",
    "G=G0.subgraph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes of G: 4639\n",
      "number of edges of G: 53312\n"
     ]
    }
   ],
   "source": [
    "# some basic information #3\n",
    "print('number of nodes of G:',G.number_of_nodes())\n",
    "print('number of edges of G:',G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.diameter(G)\n",
    "#=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define a parent class of network\n",
    "class Network:\n",
    "    R = 1\n",
    "    N = 10\n",
    "    MIN_SIZE = 4\n",
    "\n",
    "    def __init__(self, graph, homologue='4932.YKL126W', partition_method=\"nx_louvain\",partitions=[]):\n",
    "        self.graph = graph\n",
    "        self.homologue = homologue\n",
    "        self.partition_method = partition_method\n",
    "\n",
    "        self.partitions = partitions\n",
    "        self.homologue_communities = []\n",
    "        self.homologue_members={}\n",
    "        self.central_nodes = []\n",
    "        self.important_nodes = {}\n",
    "        self.homologue_index=[]\n",
    "        self.community_neighbours=[]\n",
    "        self.adjacent_communities = []\n",
    "        self.central_nodes_neighbour = [] \n",
    "        self.important_nodes_neighbour = {}\n",
    "\n",
    "        if self.partitions == []:\n",
    "            self.set_partitions_robust()\n",
    "        self.set_homologue_communities()\n",
    "        self.set_central_nodes_robust()\n",
    "        self.set_important_nodes()\n",
    "\n",
    "    def set_partitions_robust(self):\n",
    "        def find_partition(graph, partition_method, s):\n",
    "            if partition_method == \"nx_louvain\":\n",
    "                return nx_comm.louvain_communities(graph, resolution=Network.R, seed=s)\n",
    "\n",
    "            if partition_method == \"other_louvain\":\n",
    "                # some kind of community collection\n",
    "                return None\n",
    "\n",
    "        for i in range(Network.N):\n",
    "            partition = find_partition(self.graph, self.partition_method, i)\n",
    "            self.partitions.append(partition)\n",
    "\n",
    "    def set_homologue_communities(self):\n",
    "        for part in self.partitions:\n",
    "            for i in range(len(part)):\n",
    "                if self.homologue in part[i]:\n",
    "                    sub = self.graph.subgraph(part[i])\n",
    "                    self.homologue_communities.append(sub)\n",
    "                    self.homologue_index.append(i)\n",
    "                    break\n",
    "    \n",
    "    def count_homologue_comm_members(self):\n",
    "        get_subgraph_nodes = lambda x: self.graph.subgraph(x).nodes\n",
    "        homo_networks = map(get_subgraph_nodes, self.homologue_communities)\n",
    "        # count the number of subgraph each node occurs in\n",
    "        flat_comm_nodes = [y for x in homo_networks for y in x]\n",
    "        for node in list(set(flat_comm_nodes)):\n",
    "            self.homologue_members[node] = flat_comm_nodes.count(node)\n",
    "\n",
    "    def set_central_nodes_robust(self):\n",
    "        def find_central_nodes(community,n=5):\n",
    "            \"\"\"return a list of the most significant nodes\n",
    "            according to three centrality measures\"\"\"\n",
    "            deg = nx.degree_centrality(community)\n",
    "            bet = nx.betweenness_centrality(community)\n",
    "            eig = nx.eigenvector_centrality(community)\n",
    "            top_n_deg = nlargest(n, deg, key=deg.get)\n",
    "            top_n_bet = nlargest(n, bet, key=bet.get)\n",
    "            top_n_eig = nlargest(n, eig, key=eig.get)\n",
    "            return list({*top_n_deg,*top_n_bet,*top_n_eig})\n",
    "\n",
    "        \n",
    "\n",
    "        for i in range(Network.N):\n",
    "            self.central_nodes.append(find_central_nodes(self.homologue_communities[i]))\n",
    "\n",
    "\n",
    "    def set_c_nodes_neighbour(self):\n",
    "        def find_c_nodes_neighbour(community, n=3):\n",
    "            if len(community) < Network.MIN_SIZE: return []\n",
    "            deg = nx.degree_centrality(community)\n",
    "            bet = nx.betweenness_centrality(community)\n",
    "\n",
    "            top_n_deg = nlargest(n, deg, key=deg.get)\n",
    "            top_n_bet = nlargest(n, bet, key=bet.get)\n",
    "\n",
    "            return list({*top_n_deg, *top_n_deg})\n",
    "\n",
    "        for i in range(Network.N):\n",
    "            neigh_networks = map(self.graph.subgraph, self.adjacent_communities[i])\n",
    "            cen_neigh = map(find_c_nodes_neighbour, neigh_networks)\n",
    "            self.central_nodes_neighbour.append(cen_neigh)\n",
    "\n",
    "    def node_info(self, node, lst):\n",
    "        spath = nx.shortest_path(self.graph, source=self.homologue, target=node)\n",
    "        return {\n",
    "            \"times_occurred\": lst.count(node),\n",
    "            \"distance\": len(spath)\n",
    "        }\n",
    "\n",
    "    def set_important_nodes(self):\n",
    "        # flatten the central nodes list\n",
    "        flat_central_nodes = sum(self.central_nodes,[])\n",
    "        for node in set(flat_central_nodes):\n",
    "            self.important_nodes[node] = self.node_info(node, flat_central_nodes)\n",
    "\n",
    "    def set_important_nodes_neighbour(self):\n",
    "        # flatten the central nodes list\n",
    "        flat_central_nodes_1 = sum( self.central_nodes_neighbou,[])\n",
    "        flat_central_nodes_2 = sum( flat_central_nodes_1 ,[])\n",
    "        for node in set(flat_central_nodes_2):\n",
    "            self.important_nodes_neighbour[node] = self.node_info(node, flat_central_nodes_2)\n",
    "\n",
    "    def find_neighbours(self):\n",
    "        for comm in self.homologue_communities:\n",
    "            nodes = comm.nodes\n",
    "            neighs = set()\n",
    "            for n in nodes:\n",
    "                neighs.update([*self.graph.neighbors(n)])\n",
    "            self.community_neighbours.append(neighs)\n",
    "\n",
    "    def set_neighbour_communities(self):\n",
    "        a = self.partitions.copy()\n",
    "        for i, part in enumerate(a):\n",
    "            del part[self.homologue_index[i]]\n",
    "            neighs = self.community_neighbours[i]\n",
    "            # all communities containing a neighbouring element\n",
    "            nei_comm = [comm for comm in part if set(comm) & set(neighs) != set()]\n",
    "            self.adjacent_communities.append(nei_comm)\n",
    "\n",
    "    def get_partitions(self):\n",
    "        return self.partitions\n",
    "\n",
    "    def get_homologue_communities(self):\n",
    "        return self.homologue_communities\n",
    "\n",
    "    def get_central_nodes(self):\n",
    "        return self.central_nodes\n",
    "    \n",
    "    def get_important_nodes(self):\n",
    "        return self.important_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "akt2 = Network(G, '4932.YKL126W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4932.YBL016W': {'times_occurred': 9, 'distance': 4},\n",
       " '4932.YLR433C': {'times_occurred': 7, 'distance': 3},\n",
       " '4932.YDR477W': {'times_occurred': 9, 'distance': 3},\n",
       " '4932.YLR362W': {'times_occurred': 9, 'distance': 3},\n",
       " '4932.YOL012C': {'times_occurred': 1, 'distance': 3},\n",
       " '4932.YJR066W': {'times_occurred': 9, 'distance': 2},\n",
       " '4932.YMR190C': {'times_occurred': 1, 'distance': 4},\n",
       " '4932.YGR040W': {'times_occurred': 9, 'distance': 4},\n",
       " '4932.YHL007C': {'times_occurred': 4, 'distance': 3},\n",
       " '4932.YBR010W': {'times_occurred': 1, 'distance': 3},\n",
       " '4932.YNL098C': {'times_occurred': 8, 'distance': 3},\n",
       " '4932.YLR113W': {'times_occurred': 9, 'distance': 3},\n",
       " '4932.YHR030C': {'times_occurred': 9, 'distance': 3},\n",
       " '4932.YMR307W': {'times_occurred': 4, 'distance': 3},\n",
       " '4932.YKL113C': {'times_occurred': 1, 'distance': 4},\n",
       " '4932.YOR033C': {'times_occurred': 1, 'distance': 4},\n",
       " '4932.YML032C': {'times_occurred': 1, 'distance': 4},\n",
       " '4932.YER095W': {'times_occurred': 1, 'distance': 3},\n",
       " '4932.YHL022C': {'times_occurred': 1, 'distance': 4}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akt2.get_important_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for part in sorted(akt2.get_partitions(), key=lambda x:len(x)):\n",
    "#     print(len(part), sorted([len(i) for i in part],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subnet_nodes = [*{\n",
    "#     node: akt2.homologue_members[node]\n",
    "#         for node in akt2.homologue_members \\\n",
    "#             if akt2.homologue_members[node] >= 7\n",
    "# }.keys()]\n",
    "# subnet = G.subgraph(subnet_nodes)\n",
    "# nx.draw(subnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# akt2.important_nodes_neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 16, 14, 15, 10, 14, 17, 12, 16]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akt2.homologue_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# akt2.partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len([*G.neighbors(\"4932.YKL126W\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_n = akt2.adjacent_communities[0]\n",
    "# \"4932.YKL126W\" in [y for x in nodes_n for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nodes_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = akt2.partitions[0]\n",
    "# len(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('new_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365b9593587ed276fd5de7239365279e1225f9b1cb83484bb61ff6345923309a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
