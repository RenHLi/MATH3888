{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# one needs to import those packages which are needed; best to be done at the beginning of the program.\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.sparse as ss\n",
    "import random as rn\n",
    "from heapq import nlargest\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "# some basic settings for plotting figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "import numpy.linalg as LA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_score = 700\n",
    "for edge in G0.edges: \n",
    "    weight = list(G0.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G0.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the essential nodes from G0\n",
    "ess=pd.read_csv(\"essential_pro.csv\",header=None)\n",
    "ess_pro=pd.Series.to_list(ess[1])\n",
    "for i in range(len(ess_pro)):\n",
    "    ess_pro[i]='4932.'+ess_pro[i]\n",
    "G0.remove_nodes_from(ess_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow our selection to the proteins connected to ours\n",
    "nodes = nx.shortest_path(G0,'4932.YKL126W').keys()\n",
    "G=G0.subgraph(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to define a parent class of network\n",
    "class Network:\n",
    "    R = 1\n",
    "    N = 10\n",
    "    MIN_SIZE = 4\n",
    "\n",
    "    def __init__(self, graph, homologue='4932.YKL126W', partition_method=\"nx_louvain\",partitions=[]):\n",
    "        self.graph = graph\n",
    "        self.homologue = homologue\n",
    "        self.partition_method = partition_method\n",
    "\n",
    "        self._partitions = partitions\n",
    "        self.homologue_communities = []\n",
    "        self.homologue_members={}\n",
    "        self.central_nodes = []\n",
    "        self.important_nodes = {}\n",
    "        self.homologue_index=[]\n",
    "        self.community_neighbours=[]\n",
    "        self.adjacent_communities = []\n",
    "        self.central_nodes_neighbour = [] \n",
    "        self.important_nodes_neighbour = {}\n",
    "\n",
    "        if self.partitions == []:\n",
    "            self.set_partitions_robust()\n",
    "        self.set_homologue_communities()\n",
    "        self.set_central_nodes_robust()\n",
    "        self.set_important_nodes()\n",
    "\n",
    "    def set_partitions_robust(self):\n",
    "        def find_partition(graph, partition_method, s):\n",
    "            if partition_method == \"nx_louvain\":\n",
    "                return nx_comm.louvain_communities(graph, resolution=Network.R, seed=s)\n",
    "\n",
    "            if partition_method == \"other_louvain\":\n",
    "                # some kind of community collection\n",
    "                return None\n",
    "\n",
    "        for i in range(Network.N):\n",
    "            partition = find_partition(self.graph, self.partition_method, i)\n",
    "            self.partitions.append(partition)\n",
    "\n",
    "    def set_homologue_communities(self):\n",
    "        for part in self.partitions:\n",
    "            for i in range(len(part)):\n",
    "                if self.homologue in part[i]:\n",
    "                    sub = self.graph.subgraph(part[i])\n",
    "                    self.homologue_communities.append(sub)\n",
    "                    self.homologue_index.append(i)\n",
    "                    break\n",
    "    \n",
    "    def count_homologue_comm_members(self):\n",
    "        get_subgraph_nodes = lambda x: self.graph.subgraph(x).nodes\n",
    "        homo_networks = map(get_subgraph_nodes, self.homologue_communities)\n",
    "        # count the number of subgraph each node occurs in\n",
    "        flat_comm_nodes = [y for x in homo_networks for y in x]\n",
    "        for node in list(set(flat_comm_nodes)):\n",
    "            self.homologue_members[node] = flat_comm_nodes.count(node)\n",
    "\n",
    "    def set_central_nodes_robust(self):\n",
    "        def find_central_nodes(community,n=5):\n",
    "            \"\"\"return a list of the most significant nodes\n",
    "            according to three centrality measures\"\"\"\n",
    "            deg = nx.degree_centrality(community)\n",
    "            bet = nx.betweenness_centrality(community)\n",
    "            eig = nx.eigenvector_centrality(community)\n",
    "            top_n_deg = nlargest(n, deg, key=deg.get)\n",
    "            top_n_bet = nlargest(n, bet, key=bet.get)\n",
    "            top_n_eig = nlargest(n, eig, key=eig.get)\n",
    "            return list({*top_n_deg,*top_n_bet,\n",
    "            *top_n_eig\n",
    "            })\n",
    "\n",
    "        \n",
    "\n",
    "        for i in range(len(self.homologue_communities)):\n",
    "            self.central_nodes.append(find_central_nodes(self.homologue_communities[i]))\n",
    "\n",
    "\n",
    "    def set_c_nodes_neighbour(self):\n",
    "        def find_c_nodes_neighbour(community, n=3):\n",
    "            if len(community) < Network.MIN_SIZE: return []\n",
    "            deg = nx.degree_centrality(community)\n",
    "            bet = nx.betweenness_centrality(community)\n",
    "\n",
    "            top_n_deg = nlargest(n, deg, key=deg.get)\n",
    "            top_n_bet = nlargest(n, bet, key=bet.get)\n",
    "\n",
    "            return list({*top_n_deg, \n",
    "            *top_n_bet\n",
    "            })\n",
    "\n",
    "        for i in range(len(self.adjacent_communities)):\n",
    "            neigh_networks = map(self.graph.subgraph, self.adjacent_communities[i])\n",
    "            cen_neigh = map(find_c_nodes_neighbour, neigh_networks)\n",
    "            self.central_nodes_neighbour.append(cen_neigh)\n",
    "\n",
    "    def node_info(self, node, lst):\n",
    "        spath = nx.shortest_path(self.graph, source=self.homologue, target=node)\n",
    "        return {\n",
    "            \"times_occurred\": lst.count(node),\n",
    "            \"distance\": len(spath)\n",
    "        }\n",
    "\n",
    "    def set_important_nodes(self):\n",
    "        # flatten the central nodes list\n",
    "        flat_central_nodes = sum(self.central_nodes,[])\n",
    "        for node in set(flat_central_nodes):\n",
    "            self.important_nodes[node] = self.node_info(node, flat_central_nodes)\n",
    "\n",
    "    def set_important_nodes_neighbour(self):\n",
    "        # flatten the central nodes list\n",
    "        flat_central_nodes_1 = sum( self.central_nodes_neighbou,[])\n",
    "        flat_central_nodes_2 = sum( flat_central_nodes_1 ,[])\n",
    "        for node in set(flat_central_nodes_2):\n",
    "            self.important_nodes_neighbour[node] = self.node_info(node, flat_central_nodes_2)\n",
    "\n",
    "    def find_neighbours(self):\n",
    "        for comm in self.homologue_communities:\n",
    "            nodes = comm.nodes\n",
    "            neighs = set()\n",
    "            for n in nodes:\n",
    "                neighs.update([*self.graph.neighbors(n)])\n",
    "            self.community_neighbours.append(neighs)\n",
    "\n",
    "    def set_neighbour_communities(self):\n",
    "        a = self.partitions.copy()\n",
    "        for i, part in enumerate(a):\n",
    "            del part[self.homologue_index[i]]\n",
    "            neighs = self.community_neighbours[i]\n",
    "            # all communities containing a neighbouring element\n",
    "            nei_comm = [comm for comm in part if set(comm) & set(neighs) != set()]\n",
    "            self.adjacent_communities.append(nei_comm)\n",
    "\n",
    "    @property\n",
    "    def partitions(self):\n",
    "        return self._partitions\n",
    "    \n",
    "    # def get_partitions(self):\n",
    "    #     return self.partitions\n",
    "\n",
    "    def get_homologue_communities(self):\n",
    "        return self.homologue_communities\n",
    "\n",
    "    def get_central_nodes(self):\n",
    "        return self.central_nodes\n",
    "    \n",
    "    def get_important_nodes(self):\n",
    "        return self.important_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "akt2 = Network(G, '4932.YKL126W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list=enumerate(G)\n",
    "num_to_node={i[0]:i[1] for i in index_list}\n",
    "index_list=enumerate(G)\n",
    "node_to_num={i[1]:i[0] for i in index_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity_matrix(partitions):\n",
    "    N=len(partitions)\n",
    "    index_part=[]\n",
    "    for part in partitions:\n",
    "        idx=[[node_to_num[n] for n in suba] for suba in part]\n",
    "        index_part.append(idx)\n",
    "    \n",
    "    combs_idx=[]\n",
    "    for part in index_part:\n",
    "        kk=[combinations(x,2) for x in part]\n",
    "        combs_idx+=kk\n",
    "\n",
    "    aa=sum([*map(list,combs_idx)],[])\n",
    "    aa2=map(frozenset,aa)\n",
    "    cc=Counter(aa2)\n",
    "\n",
    "    sim_val=cc.values()\n",
    "    dis_val=np.array([*sim_val])\n",
    "\n",
    "\n",
    "    coord=[[*i] for i in cc.keys()]\n",
    "    coord_mat=np.array(coord)\n",
    "\n",
    "    row=np.concatenate((coord_mat[:,1],coord_mat[:,0]))\n",
    "    col=np.concatenate((coord_mat[:,0],coord_mat[:,1]))\n",
    "\n",
    "    dim=len(G.nodes)\n",
    "    dist=np.concatenate((dis_val,dis_val))\n",
    "    sim_mat=ss.coo_matrix((dist, (row, col)), shape=(dim,dim))\n",
    "\n",
    "    sim_arr=sim_mat.toarray()\n",
    "    dis_arr=1-sim_arr/N\n",
    "    np.fill_diagonal(dis_arr, 0)\n",
    "\n",
    "    return dis_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat=dissimilarity_matrix(akt2.partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=G.copy()\n",
    "F=nx.relabel_nodes(F,node_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the command for hierarchical clustering\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnes=[*map(len,akt2.partitions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_parts_complete=[]\n",
    "hier_parts_avg=[]\n",
    "for i in range(min(lnes),max(lnes)+1):\n",
    "    c_mod=AgglomerativeClustering(n_clusters = i, affinity=\"precomputed\",linkage=\"complete\")\n",
    "    hh=c_mod.fit_predict(dist_mat)\n",
    "    hier_parts_complete.append(hh)\n",
    "    c_moda=AgglomerativeClustering(n_clusters = i, affinity=\"precomputed\",linkage=\"average\")\n",
    "    hha=c_moda.fit_predict(dist_mat)\n",
    "    hier_parts_avg.append(hha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesF=np.array(list(F.nodes))\n",
    "def part_collector(hier):\n",
    "    m=max(hier)\n",
    "    coll=[set(nodesF[hier==i].tolist()) for i in range(m+1)]\n",
    "    return coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpartC=[*map(part_collector,hier_parts_complete)]\n",
    "fpartA=[*map(part_collector,hier_parts_avg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_mod=np.zeros(max(lnes)+1-min(lnes))\n",
    "A_mod=np.zeros(max(lnes)+1-min(lnes))\n",
    "for i,part in enumerate(fpartC):\n",
    "    modul=nx_comm.modularity(F,part)\n",
    "    C_mod[i]=(modul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,part in enumerate(fpartA):\n",
    "    modul=nx_comm.modularity(F,part)\n",
    "    A_mod[i]=(modul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6796802540971084\n"
     ]
    }
   ],
   "source": [
    "print(A_mod.max())\n",
    "idxA=np.where(A_mod==A_mod.max())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "intr=fpartA[idxA].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypk1_comm=[num_to_node[k] for k in intr[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=G.subgraph(ypk1_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose a title!\n",
    "title = 'Protein Network'\n",
    "\n",
    "#Establish which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [(\"Protein\", \"@index\")]\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
    "\n",
    "#Create a network graph object with spring layout\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "network_graph = from_networkx(g1, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "#Set node size and color\n",
    "network_graph.node_renderer.glyph = Circle(size=15, fill_color='skyblue')\n",
    "\n",
    "#Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n",
    "\n",
    "#Add network graph to the plot\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "show(plot)\n",
    "#save(plot, filename=f\"{title}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8\n",
    "from bokeh.transform import linear_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(nx.degree(g1))\n",
    "nx.set_node_attributes(g1, name='degree', values=degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_adjust_by = 5\n",
    "adjusted_node_size = dict([(node, degree+number_to_adjust_by) for node, degree in nx.degree(G)])\n",
    "nx.set_node_attributes(G, name='adjusted_node_size', values=adjusted_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose attributes from G network to size and color by — setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "size_by_this_attribute = 'adjusted_node_size'\n",
    "color_by_this_attribute = 'adjusted_node_size'\n",
    "\n",
    "#Pick a color palette — Blues8, Reds8, Purples8, Oranges8, Viridis8\n",
    "color_palette = Blues8\n",
    "\n",
    "#Choose a title!\n",
    "title = 'Protein network'\n",
    "\n",
    "#Establish which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [\n",
    "       (\"Protein\", \"@index\"),\n",
    "        (\"Degree\", \"@degree\")\n",
    "]\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
    "\n",
    "#Create a network graph object\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\\\n",
    "network_graph = from_networkx(g1, nx.random_layout,  center=(0, 0))\n",
    "\n",
    "#Set node sizes and colors according to node degree (color as spectrum of color palette)\n",
    "minimum_value_color = min(network_graph.node_renderer.data_source.data[color_by_this_attribute])\n",
    "maximum_value_color = max(network_graph.node_renderer.data_source.data[color_by_this_attribute])\n",
    "network_graph.node_renderer.glyph = Circle(size=size_by_this_attribute, fill_color=linear_cmap(color_by_this_attribute, color_palette, minimum_value_color, maximum_value_color))\n",
    "\n",
    "#Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n",
    "\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "show(plot)\n",
    "#save(plot, filename=f\"{title}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8\n",
    "from bokeh.transform import linear_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(nx.degree(F))\n",
    "nx.set_node_attributes(F, name='degree', values=degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_adjust_by = 5\n",
    "adjusted_node_size = dict([(node, degree+number_to_adjust_by) for node, degree in nx.degree(G)])\n",
    "nx.set_node_attributes(F, name='adjusted_node_size', values=adjusted_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Turbo256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionaries\n",
    "modularity_class = {}\n",
    "modularity_color = {}\n",
    "#Loop through each community in the network\n",
    "for community_number, community in enumerate(intr):\n",
    "    #For each member of the community, add their community number and a distinct color\n",
    "    for name in community: \n",
    "        modularity_class[name] = community_number\n",
    "        modularity_color[name] = Turbo256[community_number*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add modularity class and color as attributes from the network above\n",
    "nx.set_node_attributes(F, modularity_class, 'modularity_class')\n",
    "nx.set_node_attributes(F, modularity_color, 'modularity_color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.core.validation.check:E-1001 (BAD_COLUMN_NAME): Glyph refers to nonexistent column name. This could either be due to a misspelling or typo, or due to an expected column being missing. : key \"size\" value \"adjusted_node_size\" [renderer: GlyphRenderer(id='3813', ...)]\n"
     ]
    }
   ],
   "source": [
    "#Choose attributes from G network to size and color by — setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "size_by_this_attribute = 'adjusted_node_size'\n",
    "color_by_this_attribute = 'modularity_color'\n",
    "#Pick a color palette — Blues8, Reds8, Purples8, Oranges8, Viridis8\n",
    "color_palette = Blues8\n",
    "#Choose a title!\n",
    "title = 'Game of Thrones Network'\n",
    "\n",
    "#Establish which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [\n",
    "       (\"Character\", \"@index\"),\n",
    "        (\"Degree\", \"@degree\"),\n",
    "         (\"Modularity Class\", \"@modularity_class\"),\n",
    "        (\"Modularity Color\", \"$color[swatch]:modularity_color\"),\n",
    "]\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset, tap\", active_scroll='wheel_zoom',\n",
    "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
    "\n",
    "#Create a network graph object\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "network_graph = from_networkx(F, nx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "#Set node sizes and colors according to node degree (color as category from attribute)\n",
    "network_graph.node_renderer.glyph = Circle(size=size_by_this_attribute, fill_color=color_by_this_attribute)\n",
    "\n",
    "#Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n",
    "\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "show(plot)\n",
    "#save(plot, filename=f\"{title}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('new_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "365b9593587ed276fd5de7239365279e1225f9b1cb83484bb61ff6345923309a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
